
def beam_search_decoder(sentence , beam_width = 3):
  sentence = preTreatement(sentence)
  # convertir chaque mot to index
  inputs = [inputLang.word_index[i] for i in sentence.split(' ') if i in inputLang.word_index.keys()]
  # pad to the desired lenght
  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=maxLengthInput, padding='post')
  inputs = tf.convert_to_tensor(inputs)

  predictions = []

  predictions = tf.convert_to_tensor(predictions)

  enc_hidden = [tf.zeros((1, units))]

  encoder_output , encoder_hidden  = encoder(inputs , enc_hidden)

  decoder_hidden = encoder_hidden 


  # decoder_hidden = [decoder_hidden] * beam_width

  decoder_input = tf.expand_dims([targetLang.word_index['<start>'] ], 0) 

  # print("decoder_input" ,decoder_input[0])
  # print("decoder_hiddem:{} \n decoder_input: {} \n encoder_output :{} \n topic_vector {} \n".format(decoder_hidden.shape , decoder_input.shape , encoder_output.shape , topic_vector.shape))
  

  out , hidden, _ = decoder(decoder_input , decoder_hidden , encoder_output )
 
  index = tf.argsort(out, axis=-1, direction='DESCENDING', stable=False, name=None)

  prob = tf.sort(out ,axis = -1 , direction = 'DESCENDING')

  terminal_sentences, decoder_hidden, predictions = [], [], []

  decoder_hidden = [hidden] * beam_width

  # print(decoder_hidden)




  for i in range(beam_width):
        predictions.append(([int(index[0][i])], np.log(abs(prob[0][i]))))
      
  # print(predictions[0][0])
  
  decoder_input = [tf.expand_dims(tf.convert_to_tensor(pred[0]),0) for pred in predictions]
  # print(decoder_input[0])
      

  for t in range(1,maxLengthTarget):
        
        current_predictions = []
        for i in range(beam_width):
            out , decoder_hidden[i] , _ = decoder(decoder_input[i] , decoder_hidden[i] , encoder_output )
            # print("once")

            index = tf.argsort(out, axis=-1, direction='DESCENDING', stable=False, name=None)

            prob = tf.sort(out ,axis = -1 , direction = 'DESCENDING')

            for j in range(beam_width):
                current_predictions.append((predictions[i][0] + [int(index[0][j])] , np.log(abs(prob[0][j]**j) )+ predictions[i][1] , i))
            
        def get_prob(pred):
          return pred[1]

        current_predictions = sorted(current_predictions , key = get_prob , reverse =False)

        current_predictions = current_predictions[:beam_width]

        # print("time_step {} {}".format(t ,current_predictions))

        hidden = []
        inputs = []
        pred = []

        for j in range(beam_width):
              if targetLang.index_word[current_predictions[j][0][t]] == "<end>":
                    beam_width -= 1
                    terminal_sentences.append((current_predictions[j][0] , current_predictions[j][1]))
              else :
                    hidden.append(decoder_hidden[current_predictions[j][2]])
                    inputs.append(tf.expand_dims([tf.convert_to_tensor(current_predictions[j][0][t])],0)  )
                    pred.append((current_predictions[j][0] , current_predictions[j][1]))
        
        decoder_hidden = hidden
        decoder_input = inputs
        predictions = pred

        # print(decoder_input)

        if beam_width <+ 0 :
              break

  for x in range(len(predictions)):
        terminal_sentences.append((predictions[x][0],predictions[x][1]))

  terminal_sentences = sorted(terminal_sentences , key = get_prob , reverse =False)

  output = []

  for pred , prob in terminal_sentences:
    out = []
    s = ""
    for p  in pred:
      if targetLang.index_word[p] != "<end>":
        s += " " + targetLang.index_word[p]
      else :
        break
    output.append(s)

  prob = [pred[1] / len(output[i])  for i , pred in enumerate(terminal_sentences)]

  

  return output , prob


import numpy as np
def beam(sentence, beam_width= 2):
  output , prob =beam_search_decoder(sentence, beam_width)
  #print(f"Input : {sentence}")
  print("Questions Générées")
  amira=sorted( prob)
  for r, s in zip(output , amira):
    
    print(r.split(" <end>")[0], ": Score = ", s)
    print('*'*10)
for i in np.random.randint(0,len(df1),15):
  print('#'*20)
  print(f"INPUT : {df1['Answer'][i]}")
  print(f"la Vraie Question : {df1['Question'][i]}")
  beam(df1['Answer'][i])


